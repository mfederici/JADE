class: IRMTrainer
params:
  # Number of latent dimensions
  z_dim: 64

  #################
  # Architectures #
  #################

  # Encoder
  encoder:
    dropout: 0.25
    n_hidden: 128
    dist: Delta

  # Label classifier
  label_classifier:
    dropout: 0.0
    n_hidden: 128

  ###########################
  # Optimization parameters #
  ###########################

  # Optimizer used for the encoder and the label classifier
  optim:
    class: Adam
    params:
      lr: 0.0001

  # Size of the training batch
  batch_size: 256

  # Lowers the learning rate over time
  lr_schedule:
    class: MultiStepLR
    params:
      milestones: [ 10000 ]
      gamma: 0.1
    apply_to: [ opt ]

  # Parameters for the beta-scheduler
  beta_scheduler:
    class: LinearScheduler
    params:
      start_value: 0.5
      end_value: 0.999999
      n_iterations: 10000
      start_iteration: 5000
